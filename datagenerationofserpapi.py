"""
Google Engine Search by SerpAPI 
Python : Parse JSON file of SerpAPI, which is created by the Google search.
_____________________________________________________________________________

Project contact: Google Cloud Search API, Kyndryl
Email: gcpguild@gmail.com
Project : Python API for Google Search Engine

Use Case: 
-----------
Creating the Google Cloud Services search results in CSV from the json.
Program : parseserpapijsongooglecloud.py
----------------------------
This program is written in Python Language
Created for Lab purposes with regulations of Nature Labs

Purpose: 
----------
This program is an extension of generating the JSON file based on SerpAPI 
 
Google Search Engine API  SerpAPI. 
Google Search Key: Google Cloud Services
JSON file input: Google_services_62f1c629c7ad41d8921a6c6c.json
This program is used to parse JSON file, which is generated by Google Search API (SerpAPI) 
JSON file has the information of the Google Search Engine.
Create the necessary folders in local and download and save JSON for locally parse the search key.
Generate a many CSV files will be generated from Google Search Engine JSON.
1)	Data : Google_services_62f1c629c7ad41d8921a6c6c
2)	Folder :  C:\serpapi\python\app\nature-labs\google-cloud\data

Functionalities:
---------------
After connecting to Google Search Engine API the JSON is generated
This program is used to connect Google Search API (SerpAPI) 
Download the searched information which is saved in the JSON file based on the Google Search Engine.
Create the necessary folders in local and download and save JSON for locally parse the search key.
---------------------------------------------------------------------------------------------------
SerpAPI Sponsorship:
--------------------
Google Engine is sponsored by SerpApi. SerApi has sponsored 40,000 credits for Google search
with the API Key for scraping Google and other search engines.

On behalf of Google Engine, researchers, we express our gratitude to SerpAPI LLC, for provisioning
their sponsorship SerpAPI's sponsorship has helped us make our research and social work contribution 
for speaking out greater audience.
With the advent of SerpAPI, Google Engine has addressed our research work on Temples in India 
with the experience of a blazingly fast, super easy to use, and data-rich API in 
Google Cloud Platform Search Engine on Big Query for Research in Google Cloud Engine. 
With SerpAPI, Google Engine will be helping the student community on projects.

About SerpApi
-------------
SERP API is a real-time API to access Google search results. 
It solves the issues of having to rent proxies, solving captchas, and JSON parsing.

Design and developed by :
-------------------------
Kyndryl Solutions Private Limited
Project Team : Google Cloud Platform - Guild.
Nature Labs : Google Engine @ SerApi, LLC.

Download from Git Hub

https://github.com/gcpguild/searpapi/blob/main/parseserpapijsongooglecloud.py

How to use
------------
python parseserpapijsongooglecloud.py

Contact 
--------
Kyndryl GCP Guild Moderator: Ramamurthy V 
GCP Contact: gcpguild@gmail.com
Date: June 21, 2022.
Revised : July 8, 2022
Contributors: 122 key members from Google Cloud Search API.

For SerpAPI Key request, please write an email request with an email subject of 'request for SerpApi Key'

"""
#-----------------------------------------------------#-----------------------------------------------------
githubserpaijson = "https://github.com/gcpguild/searpapi/blob/main/parseserpapijsongooglecloud.py"

serpapijsongooglecloud = ['Google_services_62f1c629c7ad41d8921a6c6c.json']

import json, re, csv, os, unicodedata, requests, string, platform
import ijson
from bs4 import BeautifulSoup
from pathlib import Path
from six.moves.urllib.request import urlopen

import pandas as pd

import urllib.request

import numpy as np

from requests import request
from urllib.error import URLError

from itertools import filterfalse
import json, re, csv, unicodedata, string, sys, glob
from pathlib import Path
import pandas as pd
from subprocess import check_output
#----------------------------------------------------------
def removen(string):
    for m in ('\n', '\r'):
        clean_string = re.sub(m, '', string)
        clean_string = clean_string.replace(m, '')
        clean_string = clean_string.rstrip()
        clean_string = clean_string.strip(m)
        clean_string = re.sub(m,' ', clean_string)
        #C:\serpapi\python\app\nature-labs\google-cloud\data
        clean_string = [re.sub(r"[^a-zA-Z0-9.,-:-_'#@\"\/\\/]+",' ', clean_string)]
        
        mymano = ''
        for x in clean_string:
            mymano += ''+ x
        return mymano
#---------------------------------------------------
def fullyqualifydirs(mylist):
    mydircode = N.join(mylist)
    return mydircode
#-----------------------------------------------------
headers = {
    "User-Agent":
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3538.102 Safari/537.36 Edge/18.19582"
}
#-----------------------------------------------------------
def prt(p):

    width = len(p) + 4
    print('┏' + "━"*width + "┓")
    print('┃' + p.center(width) + '┃')
    print('┗' + "━"*width + "┛")
#-------------------------------------------------------
myos = platform.system()

if (myos == "Linux" or myos == "linux2"):
    # linux
    N="/"
    homedirectory = str(Path.home())
    mylist = [ homedirectory, 'serpapi/python/app/nature-labs/google-cloud' ]
    basedir = fullyqualifydirs(mylist)
   
elif myos == "win32" or myos == "Windows":
    # Windows 
    N="\\"    
    basedir = 'C:\\serpapi\\python\\app\\nature-labs\\google-cloud'  
#--------------------------------------------------------------
if not basedir:
    basedir = os.getcwd()
#-----------------------------------------------------------------------------------------------------
mylist = [basedir, 'initialization.py']
initialdirectoryconfig = fullyqualifydirs(mylist)
#------------------------------------------------------------------------------------------------------
getdirectory = removen(check_output([sys.executable, initialdirectoryconfig], universal_newlines=True))

mylist = [ getdirectory, serpapijsongooglecloud[0] ]
googlecloudservicejson = fullyqualifydirs(mylist)

path = Path(googlecloudservicejson)

if not path.is_file():
    pi="\'SerpAPI JSON data is missing: \' :"
    p = ("{} {}".format(pi,googlecloudservicejson))
    prt(p)
    exit(1)
#-----------------------------------------------------
#-----------------------------------------------------
def mkingdirs(givenlist):
    mymanog = N.join(givenlist)
    mk_dir = Path(mymanog)
    mk_dir.mkdir(parents=True, exist_ok=True)
    return mk_dir
#-------------------------------------------------------------------
myoutdir = [getdirectory, 'output' ]
outputdir = mkingdirs(myoutdir)
#-------------------------------------------------------------------------------
def dataadding(filename, modetw, k, li, keying, jd, l):
    
    if (l == 'y'):
        cleantemples = []
        for i in range(0,li):
            gor = ''
            gor = removen(jd[k][i][keying])
            l = cleantemples.append(gor)

    tf = pd.DataFrame(l)
    tf.to_csv(filename, encoding='utf-8', mode=modetw, index=False, header = False)
#---------------------------------------------------------------------------------
def gematerials(k, jd): 
    csvdatasheet = ("{}{}".format(k,'.csv'))
    mylist = [ getdirectory, 'output' , csvdatasheet ]
    templesserpapifilterdata = fullyqualifydirs(mylist)
    
    li = ''
    keying = ''
    li = len(jd[k])
    modetw = 'w' if k else 'a'
    
   
    if (k == 'inline_images'):
        keying = ''
        keying = 'thumbnail'
        dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = 'y')
    
    if (k == 'sports_results'):
        results = jd[k]     
        cleantemples = [] 
        for impk, impv in results.items():
            nd = []
            nd = [ impk, impv ]

            cleantemples.append(nd)
            dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
    
    if (k == 'search_metadata'):
        results = jd[k]
        cleantemples = []
        for impk, impv in results.items():
            nd = []
            nd = [ impk, impv ]
            cleantemples.append(nd)
            dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
    #inline_images
    if (k == 'inline_images'):
        results = jd[k]
        cleantemples = []

        for r in results:
            for impk, impv in r.items():
                nd = []
                nd = [ impk, impv ]
                cleantemples.append(nd)

        dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
 
    if (k == 'related_questions'):
        results = jd[k]
        cleantemples = []

        for r in results:
            for impk, impv in r.items():
                nd = []
                if (impk != 'next_page_token'):
                    nd = [ impk, impv ]
                    cleantemples.append(nd)

        dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
   
    if (k == 'organic_results'):
        results = jd[k]
        cleantemples = []
        lo = len(results)
        for l in range(0,lo):
    
            for impka, impva in results[l].items():
                nol = []
                ncv = re.sub(r"\\u200e", ",", removen(str(impva)))
                nol = [ impka, ncv ]
                if (impka == 'sitelinks'):
                    
                    ltwa = len(impva)
                    for impk, impv in impva.items():
                        if (impk == 'expanded'):
                         
                            for e in (impv):
                              
                                for (ik, iv) in e.items():
                                    for g in range(3):
                                        pri = re.sub(r"[^0-9]+",'', str(np.random.uniform(0,2,1)))
                    
                                    lt = ("{}{}{}".format(ik, '_', pri))
                                    nai = []
                                    nai = [lt, removen(iv) ]
                                    cleantemples.append(nai)
                                   
                if (impka == 'related_results'):
                    for t in impva:
                        
                        for (ik, iv) in t.items():
                            for g in range(3):
                                pri = re.sub(r"[^0-9]+",'', str(np.random.uniform(0,2,1)))
                            lb = ("{}{}{}".format(ik, '_', pri))
                            nai = []
                            ncvi = re.sub(r"\\u200e", ",", removen(str(iv)))
                            
                            nai = [lb, ncvi ]
                            cleantemples.append(nai)
                        
                else:
                    
                    cleantemples.append(nol)
                dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
    
#----------------------------------------------------------------------------------------------
    if (k == 'search_parameters'):
        results = jd[k]
        cleantemples = []
        for impk, impv in results.items():
            nd = []
            nd = [ impk, impv ]
            cleantemples.append(nd)
            dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
#------------------------------------------------------------------------------------------------------------------------------    
#----------------------------------------------------------------------------------------------
    if (k == 'related_searches'):
        results = jd[k]
        cleantemples = []
        for r in range(0,len(results)):
            for impk, impv in results[r].items():
                for g in range(3):
                    pri = re.sub(r"[^0-9]+",'', str(np.random.uniform(0,2,1)))
                    lb = ("{}{}{}".format(impk, '_', pri))
                nd = []
                nd = [ lb, impv ]
                cleantemples.append(nd)
        dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
#-----------------------------------------------------------------------------------------
    if (k == 'search_information'):
        results = jd[k]
        cleantemples = []
        for impk, impv in results.items():
            nd = []    
            if (impk == 'menu_items'):
                for e in impv:
                    for (ik, iv) in e.items():
                        for g in range(3):
                            pri = re.sub(r"[^0-9]+",'', str(np.random.uniform(0,2,1)))
                        lt = ("{}{}{}".format(ik, '_', pri))
                    nd = [ impk, e ]
                    cleantemples.append(nd)
            else:
                nd = [ impk, impv ]
                cleantemples.append(nd)
            dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
#-------------------------------------------------------------------------------------------------------------------------------------    
    if (k == 'knowledge_graph'):
        results = jd[k]
        cleantemples = []
        for impk, impv in results.items():
            nd = []
            nd = [ impk, impv ]    
         
            if (impk == 'source'):   
                for (ik, iv) in impv.items():
                    
                    for g in range(3):
                        pri = re.sub(r"[^0-9]+",'', str(np.random.uniform(0,2,1)))
                    lbu = ("{}{}{}".format(ik, '_', pri))
                    nai = [] 
                    nai = [lbu, iv ]
                    
                    cleantemples.append(nai)
              
            if (impk == 'owner_links'): 
                for e in impv:
                    
                    for (ik, iv) in e.items():
                      
                        for g in range(3):
                            pri = re.sub(r"[^0-9]+",'', str(np.random.uniform(0,2,1)))
                        lbl = ("{}{}{}".format(ik, '_', pri))
                        nail = []
                        nail = [lbl, removen(str(iv)) ]
                        cleantemples.append(nail)
            else: 
                cleantemples.append(nd)
            dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
#--------------------------------------------------------------------------------------------------------------------------------------    
    if (k == 'ads'):
        results = jd[k]
        cleantemples = []
        lr = len(results)
        for l in range(0,lr):
    
            for impka, impva in results[l].items():
                na = []
                ncv = re.sub(r"\\u200e", ",", removen(str(impva)))
                na = [ impka, ncv ]
                if (impka == 'sitelinks'):
                     ltwa = len(impva)
                     for i in range(0,ltwa):
                        lt = ("{}{}{}".format('title', '_',i))
                        nai = []
                        nai = [lt, removen(impva[i]['title']) ]
                        cleantemples.append(nai)
                        ll = ("{}{}{}".format('link', '_',i))
                        nal = []
                        nal = [ll, impva[i]['link'] ]
                        cleantemples.append(nal)
                else:
                    cleantemples.append(na)
                dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
    #-------------------------------------------------------------------------------------
    if (k == 'twitter_results'):
        results = jd[k]
        cleantemples = []
        for impk, impv in results.items():
            nd = []
            nd = [ impk, impv ]
            
            if (impk == 'tweets'):
                ltw = len(impv)
                
                for i in range(0,ltw):
                    li = ("{}{}{}".format('link', '_',i))
                    nd = []
                    nd = [li, impv[i]['link']]
                    si = ("{}{}{}".format('snippet', '_',i))
                    ns = []
                    
                    ns = [si, removen(impv[i]['snippet'])]
                    pi = ("{}{}{}".format('published_date', '_',i))
                    pubd = [pi, impv[i]['published_date']]
                    
                    cleantemples.append(ns)
                    cleantemples.append(nd)
                    cleantemples.append(pubd)
            else:
                cleantemples.append(nd)

            dataadding( filename = templesserpapifilterdata,modetw = modetw, k = k,li = li, keying = keying, jd = jd, l = cleantemples)
    else:
        pass

#-----------------------------------------------------------------------------------------

with open(googlecloudservicejson,"r", encoding="utf-8") as jf:
    data = json.load(jf)

for key, value in data.items():
    templesgooglengine = []
    gematerials(k = key, jd = data)
#-----------------------------------------

